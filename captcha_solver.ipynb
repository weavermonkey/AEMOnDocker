{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "captcha_solver",
      "provenance": [],
      "authorship_tag": "ABX9TyMPM4OxatwrGoZC4+k9NSlU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weavermonkey/AEMOnDocker/blob/master/captcha_solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLEnXbJOdrU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import imutils\n",
        "from imutils import paths\n",
        "import os\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXSPSImYksxl",
        "colab_type": "code",
        "outputId": "68452024-7512-4cac-c8fd-10ed6079bd8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "SOLVED_CAPTCHA_FOLDER = \"images\"\n",
        "OUTPUT_FOLDER = \"extracted_letters\"\n",
        "solved_captchas = glob.glob(os.path.join(SOLVED_CAPTCHA_FOLDER, \"*\"))\n",
        "counts = {}\n",
        "for (i, captcha) in enumerate(solved_captchas):\n",
        "    filename = os.path.basename(captcha)\n",
        "    captcha_text = os.path.splitext(filename)[0]\n",
        "    image = cv2.imread(captcha)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "    thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV, cv2.THRESH_OTSU)[1]\n",
        "    contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    letter_image_regions = []\n",
        "\n",
        "    for contour in contours:\n",
        "      (x, y, w, h) = cv2.boundingRect(contour)\n",
        "      if w / h > 1.25:\n",
        "        half_width = int(w / 2)\n",
        "        letter_image_regions.append((x, y, half_width, h))\n",
        "        letter_image_regions.append((x + half_width, y, half_width, h))\n",
        "      else:\n",
        "        letter_image_regions.append((x, y, w, h))\n",
        "    letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])\n",
        "\n",
        "    for letter_bounding_box, letter_text in zip(letter_image_regions, captcha_text):\n",
        "      x, y, w, h = letter_bounding_box\n",
        "      letter_image = gray[y - 2:y + h + 2, x - 2:x + w + 2]\n",
        "      save_path = os.path.join(OUTPUT_FOLDER, letter_text)\n",
        "      if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "      count = counts.get(letter_text, 1)\n",
        "      p = os.path.join(save_path, \"{}.png\".format(str(count)))\n",
        "      cv2.imwrite(p, letter_image)\n",
        "      counts[letter_text] = count + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-70238331cb38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter_text\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl59ndoc11gC",
        "colab_type": "code",
        "outputId": "8882ee80-c16c-4cb0-8ecb-6405f26d744a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "letter_folder = 'extracted_letters'\n",
        "data = []\n",
        "labels = []\n",
        "for image in paths.list_images(letter_folder):\n",
        "    img = cv2.imread(image)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (30,30))\n",
        "    img = np.expand_dims(img, axis = 2)\n",
        "    label = image.split(os.path.sep)[-2]\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "data = np.array(data, dtype = \"float\")\n",
        "labels = np.array(labels)\n",
        "print(data.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(83, 30, 30, 1) (83,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mny7cQAK16aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data/255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI6Tq5O82ZDI",
        "colab_type": "code",
        "outputId": "8cae5b86-02c0-497b-9c10-71bb41cb59b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "(train_x, val_x, train_y, val_y) = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
        "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66, 30, 30, 1) (17, 30, 30, 1) (66,) (17,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HbfvcD-2bMb",
        "colab_type": "code",
        "outputId": "fb748569-5a42-4561-a6e0-29fe2a107b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pickle\n",
        "lb = LabelBinarizer().fit(train_y)\n",
        "train_y = lb.transform(train_y)\n",
        "val_y = lb.transform(val_y)\n",
        "\n",
        "bin = pickle.dumps(lb)\n",
        "with open(\"captcha_labels.pickle\", \"wb\") as f:\n",
        "    pickle.dump(lb, f)\n",
        "\n",
        "print(train_y.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66, 18) (17, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VykRnia2dEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Om2H0E2f8l",
        "colab_type": "code",
        "outputId": "4dc9d1cf-4f86-43da-beb8-cb37492a47ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(30, 30, 1), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(18, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 30, 30, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               627456    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 18)                4626      \n",
            "=================================================================\n",
            "Total params: 657,652\n",
            "Trainable params: 657,652\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgQ6h_XT2iew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estop = EarlyStopping(patience=10, mode='min', min_delta=0.001, monitor='val_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cffqxQtx2mdg",
        "colab_type": "code",
        "outputId": "e7c3a679-d640-4109-b4ed-fce9df76d7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=32, epochs=50, verbose=1, callbacks = [estop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66 samples, validate on 17 samples\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 111.1150 - accuracy: 0.0606 - val_loss: 47.1671 - val_accuracy: 0.1765\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 68.2238 - accuracy: 0.0606 - val_loss: 26.6556 - val_accuracy: 0.0588\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 24.9162 - accuracy: 0.1515 - val_loss: 8.2834 - val_accuracy: 0.0588\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 6.3091 - accuracy: 0.1667 - val_loss: 3.9204 - val_accuracy: 0.1765\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 2.9077 - accuracy: 0.3182 - val_loss: 3.1487 - val_accuracy: 0.1765\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 2.2159 - accuracy: 0.3788 - val_loss: 2.7641 - val_accuracy: 0.1765\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 1.8247 - accuracy: 0.3788 - val_loss: 2.5810 - val_accuracy: 0.2941\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 1.7621 - accuracy: 0.5000 - val_loss: 2.4489 - val_accuracy: 0.2941\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 1.3829 - accuracy: 0.6212 - val_loss: 2.5068 - val_accuracy: 0.3529\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 1.1127 - accuracy: 0.7121 - val_loss: 2.8456 - val_accuracy: 0.4118\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.8986 - accuracy: 0.7576 - val_loss: 3.1414 - val_accuracy: 0.4118\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.8030 - val_loss: 3.1903 - val_accuracy: 0.4118\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.8485 - val_loss: 3.0023 - val_accuracy: 0.2941\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8636 - val_loss: 2.8892 - val_accuracy: 0.4706\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9394 - val_loss: 2.8976 - val_accuracy: 0.4706\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9091 - val_loss: 2.8581 - val_accuracy: 0.4706\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.9242 - val_loss: 2.8315 - val_accuracy: 0.4706\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9697 - val_loss: 2.8899 - val_accuracy: 0.4706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa49af8d048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT_B1Qfz2rki",
        "colab_type": "code",
        "outputId": "e8201f34-befb-4f68-ef61-012a1c573da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNAdJ7rwAOza",
        "colab_type": "code",
        "outputId": "559bd96c-c8e3-4fa4-8730-eed76d89a4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "image = cv2.imread('/content/images/PPAJAR.jpg')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV, cv2.THRESH_OTSU)[1]\n",
        "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "letter_image_regions = []\n",
        "for contour in contours:\n",
        "    # Get the rectangle that contains the contour\n",
        "    (x, y, w, h) = cv2.boundingRect(contour)\n",
        "    \n",
        "    # checking if any counter is too wide\n",
        "    # if countour is too wide then there could be two letters joined together or are very close to each other\n",
        "    if w / h > 1.25:\n",
        "        # Split it in half into two letter regions\n",
        "        half_width = int(w / 2)\n",
        "        letter_image_regions.append((x, y, half_width, h))\n",
        "        letter_image_regions.append((x + half_width, y, half_width, h))\n",
        "    else:\n",
        "        letter_image_regions.append((x, y, w, h))\n",
        "            \n",
        "\n",
        "# Sort the detected letter images based on the x coordinate to make sure\n",
        "# we get them from left-to-right so that we match the right image with the right letter  \n",
        "\n",
        "letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])\n",
        "\n",
        "# Create an output image and a list to hold our predicted letters\n",
        "output = cv2.merge([gray] * 3)\n",
        "predictions = []\n",
        "    \n",
        "# Creating an empty list for storing predicted letters\n",
        "predictions = []\n",
        "    \n",
        "# Save out each letter as a single image\n",
        "for letter_bounding_box in letter_image_regions:\n",
        "    # Grab the coordinates of the letter in the image\n",
        "    x, y, w, h = letter_bounding_box\n",
        "\n",
        "    # Extract the letter from the original image with a 2-pixel margin around the edge\n",
        "    letter_image = gray[y - 2:y + h + 2, x - 2:x + w + 2]\n",
        "\n",
        "    letter_image = cv2.resize(letter_image, (30,30))\n",
        "        \n",
        "    # Turn the single image into a 4d list of images\n",
        "    letter_image = np.expand_dims(letter_image, axis=2)\n",
        "    letter_image = np.expand_dims(letter_image, axis=0)\n",
        "\n",
        "    # making prediction\n",
        "    pred = model.predict(letter_image)\n",
        "        \n",
        "    # Convert the one-hot-encoded prediction back to a normal letter\n",
        "    letter = lb.inverse_transform(pred)[0]\n",
        "    #predictions.append(letter)\n",
        "    print((letter))\n",
        "\n",
        "'''\n",
        "\n",
        "    # draw the prediction on the output image\n",
        "    try:\n",
        "      cv2.rectangle(output, (x - 2, y - 2), (x + w + 4, y + h + 4), (0, 255, 0), 1)\n",
        "      cv2.putText(output, letter, (x - 5, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "#captcha_text = \"\".join(predictions)\n",
        "#print(\"CAPTCHA text is: {}\".format(captcha_text))\n",
        "plt.imshow(output)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n    # draw the prediction on the output image\\n    try:\\n      cv2.rectangle(output, (x - 2, y - 2), (x + w + 4, y + h + 4), (0, 255, 0), 1)\\n      cv2.putText(output, letter, (x - 5, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)\\n    except Exception as e:\\n      pass\\n\\n#captcha_text = \"\".join(predictions)\\n#print(\"CAPTCHA text is: {}\".format(captcha_text))\\nplt.imshow(output)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3EQ4JTtPIxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}